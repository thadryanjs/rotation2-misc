
```{julia}

using Random
using Distributions
using Plots
using DataFrames
using CSV
```

## Definitions

 - $N$:= numbers of observations per sample.
 - $K$:= number batches (can be thought of as number of bootstraps).
 - $M$:= number of observations per batch ($\frac{N}{K}$).
 - $\theta$:= mean of a sample.
 - $\theta^{b}$:= mean of a batch (bootstrap).
 - $\sigma$:= standard deviation of sample.
 - $\sigma_b$:= standard deviation of a batch.
 - $R$:= root statistic comparing two means (an empirical mean to a bootstrap).
 - $S$:= standard error of a sample ("Outer SE").
 - $S_b$:= standard error use in the calculation of $R$ ("Inner SE").
 - $\alpha$:= significance level of a comparison.
 - $d$:= $1-\alpha$ quantile of a vector of $R$s.
 - $Z$:= $\in [N,M,K]$, factor to test the use of in the function.


```{julia}

Random.seed!(8675309)

N = 1000
K = Int(N/10)
M = Int(N/K)

println("N: ", N, ", K: ", K, ", M:", M)
```

The log-normal distribution:

$$
X \sim Normal(\mu, \sigma)
$$

Then:
$$
exp(X) \sim LogNormal(\mu,\sigma)
$$

## Mathematical Functions

These are the functions we're using for math calculations (as opposed to the programmatic, automation/simulation functions).

### Standard Error $S$

The classical standard error.

```{julia}

# compute the standard error
function standard_error(sd1, sd2, N)
    sqrt( ( (sd1^2) + (sd2^2) ) * (N^-1) )
end
```

### Standard Error for a batch $S_b$

The standard error modified for our tests

```{julia}

# Z will be either N, M, K
function standard_error_boot(sd1, sd2, Z)
    sqrt( ( (sd1^2) + (sd2^2) ) * (Z^-1) )
end 
```



### Computing $R$

```{julia}

# Compute the root statistic
function calc_root_stat(m1, m1b, m2, m2b, se)
    abs( (m1b - m2b) - (m1 - m2)/se )
end
```


## Simulation Functions

```{julia}

function generate_sample(mu, sd, N)

    exp_vector(vec) = [exp(i) for i in vec]

    exp_vector(rand(Normal(mu, sd), N))

end

samples = [generate_sample(2, 0.5, N) for i in 1:2]

histogram(samples[1])
```

I will now write a separate function to get the information about sample needed to make a comparison.

### Getting batch info

```{julia}

### will conduct batch bootstrapping and collect relevant data on the sample
function get_batch_info(sample, sample_name, K)    

    # arrays to store means and SDs
    theta_boots = []
    sd_boots = []

    # this algorithm indexes arrays at...
    # 1-100
    # 101-200
    # 201-300
    # etc
    i = 1
    for x in 1:K
        # the upper limits, ie, 1-100
        j = i  + (M-1)
        batch = sample[i:j]
        ### (debug) println("from ", i, " to ", j)
        # collect the figures
        push!(theta_boots, mean(batch))
        push!(sd_boots, std(batch))
        # increase by the batch size the set the next limit
        i += M
    end
    
    Dict(
        "name" => sample_name,
        "mean" => mean(sample),
        "sd" => std(sample),
        "bootstrap_means" => theta_boots,
        "bootstrap_sds" => sd_boots
    )

end

sample1 = get_batch_info(samples[1], "sample1", K)
```

Now we have a dictionary containing the information about a samples we need to compare it to another. We will get another sample to compare it to.

```{julia}
sample2 = get_batch_info(samples[2], "sample2", K)
```

### Pairwise comparison

```{julia}

### makes comparisons and returns a vector of R statistics
### z is the N, K, or M we're testing
function pairwise_comparison(sample1, sample2, Z)

    # get relevant sample information
    s1_theta = sample1["mean"]
    s1_theta_boots = sample1["bootstrap_means"]
    s1_sd_boots = sample1["bootstrap_sds"]

    s2_theta = sample2["mean"]
    s2_theta_boots = sample2["bootstrap_means"]
    s2_sd_boots = sample2["bootstrap_sds"]

    # a vector to collect the R statistics
    R_stats = []

    # the number of iterations must match the number of batches, K
    for i in 1:K
        # get the standard error using the current batch sd
        se = standard_error(s1_sd_boots[i], s2_sd_boots[i], Z)
        
        R = calc_root_stat(s1_theta, s1_theta_boots[i],
                            s2_theta, s2_theta_boots[i], se)
        push!(R_stats, R)
    end

    R_stats

end
```

```{julia}

R_stats_N = pairwise_comparison(sample1, sample2, N)
histogram(R_stats_N)
```

```{julia}

R_stats_K = pairwise_comparison(sample1, sample2, K)
histogram(R_stats_K)
```

```{julia}

R_stats_M = pairwise_comparison(sample1, sample2, M)
histogram(R_stats_M)
```



```{julia}


m1 = sample1["mean"]
sd1 = sample1["sd"]

m2 = sample2["mean"]
sd2 = sample2["sd"]

d = quantile(R_stats_K, 1-0.05)

global_se = standard_error(sd1, sd2, N)

println("low ", (m1 - m2) - (d*global_se) )
println("observed ", (m1 - m2))
println("high ", (m1 - m2) + (d * global_se) )
```




```{julia}

samples_per_experiment = 1000
samples = []

for i in 1:100
    s = generate_sample(2, 0.5, N)
    sr = get_batch_info(s, string("sample", i), K)
    push!(samples, sr)
end
```

## The simulation

```{julia}

function run_simulation(samples, Z)

    comparison = []

    lower = []
    observed = []
    upper = []

    r_stats_dict = Dict()

    for i in 1:length(samples)
        for j in 1:length(samples)
            if i != j

                # unpack what we'll need
                s1 = samples[i]
                s2 = samples[j]

                m1 = s1["mean"]
                m2 = s2["mean"]

                sd1 = s1["sd"]
                sd2 = s2["sd"]
                
                # note the comparison for the record
                c = string(i, "_vs_", j)
                
                # make the comparison to get the root stats
                r_stats = pairwise_comparison(s1, s2, Z)
                
                # compute the "outer se" of the comparison
                ### note that the Z we're using is N
                global_se = standard_error(sd1, sd2, N)

                # get the d statistic
                d = quantile(r_stats, 1-0.05)

                l = (m1 - m2) - (d * global_se)
                o = (m1 - m2)
                u = (m1 - m2) + (d * global_se)

                push!(comparison, c )
                push!(lower, l)
                push!(observed, o)
                push!(upper, u)

                r_stats_dict[comparison] = r_stats

            end
        end
    end

    (
        DataFrame(
            comparison = comparison,
            lower = lower, 
            observed = observed,
            upper = upper,
        ),

        r_stats_dict
    )

end
```

```{julia}

sim_N = run_simulation(samples, N)

nrow(sim_N[1])

df = sim_N[1]

first(df, 5)
```


### Using N

```{julia}

function extract_all_rstats(d)
    
    r_stats = []

    for (k, v) in d
        for i in v
            push!(r_stats, i)
        end
    end

    r_stats

end

```

```{julia}

sim_N = run_simulation(samples, N)

first(sim_N[1], 10)

CSV.write("outputs/sim_N.csv", sim_N[1])

histogram(extract_all_rstats(sim_N[2]))
```

```{julia}
nrow(sim_N[1])
```

### Using K

```{julia}

sim_K = run_simulation(samples, K)

first(sim_K[1], 10)

CSV.write("outputs/sim_K.csv", sim_K[1])

histogram(extract_all_rstats(sim_K[2]))
```


### Using M

```{julia}

sim_M = run_simulation(samples, M)

first(sim_M[1], 10)

CSV.write("outputs/sim_M.csv", sim_M[1])

histogram(extract_all_rstats(sim_M[2]))
```


```{julia}
println("End...")
```

Can I just slurp out all the Rs and make a histogram for each one? They're the same distribution

```{julia}

```
